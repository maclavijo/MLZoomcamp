{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, AdaBoostClassifier,RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, RocCurveDisplay, brier_score_loss\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba29aa6",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c282f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = 42\n",
    "url='Datasets/diabetes_dataset.csv'\n",
    "\n",
    "def getData(url = url):\n",
    "\n",
    "    url = url\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def cleanData(url = url):\n",
    "\n",
    "    #Drop duplicates\n",
    "    print('Dropping duplicates...\\n')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "    #Change all column names to lower case\n",
    "    print('Converting to lower case columns and data...')\n",
    "    df.columns = df.columns.str.replace('Diabetes_binary','diabetes').str.lower()\n",
    "\n",
    "    #This next for loop doesn't get executed because there are no \"object\" type columns\n",
    "    for col in df.select_dtypes(object).columns:\n",
    "        df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def splitData(df):\n",
    "\n",
    "    target = df.diabetes\n",
    "    data = df.drop(columns=['diabetes'])\n",
    "    dfTrainFull, dfTest, yTrainFull, yTest = train_test_split(data, target, test_size=0.2, random_state=randomState)\n",
    "    dfTrain, dfVal, yTrain, yVal = train_test_split(dfTrainFull, yTrainFull, test_size=0.25, random_state=randomState)\n",
    "\n",
    "    print(  f'Dataset has been split in: Training set with {len(yTrain)} samples, '\n",
    "            f'Validation set with {len(yVal)} samples and Test set with {len(yTest)} samples')\n",
    "\n",
    "    return dfTrainFull, yTrainFull, dfTrain, yTrain, dfVal, yVal, dfTest, yTest\n",
    "\n",
    "def printHelper(f1Score, auc):\n",
    "    \n",
    "    print('\\n---------------------------------')\n",
    "    print(f'Test set weighted f1-score: {f1Score}')\n",
    "    print(f'Test set auc: {auc}')\n",
    "    print('---------------------------------\\n')\n",
    "\n",
    "def printResults(results):  \n",
    "    print('\\n-----------------------------------------')\n",
    "    for i,j in results.items():\n",
    "        print('{:<20}:  {:<6}'.format(i, \" Â± \".join([str(x) for x in j])))\n",
    "    print('-----------------------------------------')\n",
    "\n",
    "    \n",
    "def getMeasures(model):\n",
    "\n",
    "    yTestpredProb = model.predict_proba(dfTest)[:,1]\n",
    "    yTestpred = model.predict(dfTest)\n",
    "    auc = round(roc_auc_score(yTest, yTestpredProb),3)\n",
    "    f1Score = round(f1_score(yTest, yTestpred, average='weighted'),3)\n",
    "    modelName = type(model.named_steps.classifier).__name__\n",
    "\n",
    "    printHelper(f1Score, auc)\n",
    "\n",
    "    print(classification_report(yTest, yTestpred))\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(14, 6))\n",
    "    fpr, tpr, _ = roc_curve(yTest.values, yTestpredProb)\n",
    "    roc_display1 = RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=ax1, name=f'ROC_AUC {modelName}', )\n",
    "    ax1.text(0.4,0.5,f'auc = {auc}', size=14, fontweight='semibold', )\n",
    "    ax1.text(0.4,0.4,f'Weighted f1  = {f1Score}', size=14, fontweight='semibold')\n",
    "    ax1.legend(loc=4, prop={'size': 20})\n",
    "\n",
    "    print()\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1,2, figsize=(16, 6))\n",
    "    ax2[0].grid(False)\n",
    "    ax2[1].grid(False)\n",
    "\n",
    "    cm = confusion_matrix(yTest, yTestpred)\n",
    "    cmprob = confusion_matrix(yTest, yTestpred, normalize='true')\n",
    "    cm_display1 = ConfusionMatrixDisplay(cm, display_labels=['No-Diabetes', 'Diabetes'])\n",
    "    cm_display2 = ConfusionMatrixDisplay(cmprob, display_labels=['No-Diabetes', 'Diabetes'])\n",
    "\n",
    "    cm_display1.plot(ax=ax2[0])\n",
    "    cm_display1.ax_.set_title(\"Confusion Matrix\", size=16)\n",
    "    cm_display2.plot(ax=ax2[1])\n",
    "    cm_display2.ax_.set_title(\"Narmalized Confusion Matrix\", size=16)\n",
    "\n",
    "    return [auc], [f1Score]#, yTestpred, yTestpredProb\n",
    "\n",
    "def getResults(model, params):\n",
    "    \n",
    "    baseParams = [\"mean_train_auc\",\n",
    "                  \"std_train_auc\",\n",
    "                  \"rank_test_auc\",\n",
    "                  \"mean_train_f1_weighted\",\n",
    "                  \"std_train_f1_weighted\",\n",
    "                  \"rank_test_f1_weighted\"\n",
    "    ]\n",
    "    \n",
    "    allParams = baseParams + params\n",
    "    \n",
    "    cv_results = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "    res = cv_results[allParams]\n",
    "    \n",
    "    if 'param_classifier__reg_lambda' not in params:\n",
    "        display(res.query('rank_test_auc < 30 & rank_test_f1_weighted < 30').sort_values(by=[\"rank_test_auc\", \"rank_test_f1_weighted\"]))\n",
    "    else:\n",
    "        display(res.sort_values(by=[\"rank_test_auc\", \"rank_test_f1_weighted\"]).head(20))\n",
    "\n",
    "def getBestModelResults(model):\n",
    "    \n",
    "    cv_results = cross_validate(model,\n",
    "                                dfTrainFull,\n",
    "                                yTrainFull,\n",
    "                                cv=outerCV,\n",
    "                                scoring=['f1_weighted','roc_auc'],\n",
    "                                n_jobs=-1,\n",
    "                                return_train_score=True,\n",
    "                                return_estimator=True,\n",
    "    )\n",
    "\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    cv_test_scores = cv_results[['test_f1_weighted', 'train_f1_weighted', 'test_roc_auc', 'train_roc_auc']]\n",
    "    cv_test_scores.columns = ['val_f1_weighted', 'val_roc_auc','train_f1_weighted', 'train_roc_auc']\n",
    "    \n",
    "    print(\"Scores after hyperparameters tuning:\\n\")\n",
    "    \n",
    "    res = cv_test_scores.copy()\n",
    "    res.loc['mean'] = res.mean().round(4)\n",
    "    res.loc['std'] = res.std().round(4)\n",
    "    \n",
    "    results = {}\n",
    "    for col in res:\n",
    "        print('{:<20}:  {:<6} +/- {:<6}'.format(col, res.loc[\"mean\"][col], res.loc[\"std\"][col]))\n",
    "        #print(f'{col}: {res.loc[\"mean\"][col]} +/- {res.loc[\"std\"][col]}')\n",
    "        results[col] = [res.loc[\"mean\"][col], res.loc[\"std\"][col]]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def reload(module):\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093cf25",
   "metadata": {},
   "source": [
    "### Load binary unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getData()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff5d6c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112d549",
   "metadata": {},
   "source": [
    "#### Preparing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ee2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleanData(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10c09f",
   "metadata": {},
   "source": [
    "#### Checking Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "corr_matrix = df.corr().abs()\n",
    "plt.figure(figsize=(17,17))\n",
    "\n",
    "_ = sns.heatmap(corr_matrix, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_matrix.diabetes.sort_values(ascending=False).hist()\n",
    "sns.set_theme()\n",
    "dfMatrix = df.drop(columns='diabetes')\n",
    "corr_matrix = dfMatrix.corrwith(df.diabetes).abs()\n",
    "plt.figure(figsize=(14,5))\n",
    "_ = corr_matrix.plot(kind='bar', grid=True)\n",
    "_ = plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7815f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb53f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['nodocbccost', 'fruits', 'anyhealthcare', 'veggies'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fa89b",
   "metadata": {},
   "source": [
    "#### The target value is heavily imbalanced.  No Diabetes- 194377, Diabetes- 35097."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_= df.hist(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainFull, yTrainFull, dfTrain, yTrain, dfVal, yVal, dfTest, yTest = splitData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61434576",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67678923",
   "metadata": {},
   "source": [
    "This part will be used for the Logistic Regression classifier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18645d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = ['highbp', 'highchol', 'cholcheck','smoker','stroke',\n",
    "                   'heartdiseaseorattack', 'physactivity', 'hvyalcoholconsump',\n",
    "                   'genhlth','diffwalk', 'sex', 'education']\n",
    "\n",
    "numericalCols = ['bmi', 'menthlth', 'physhlth', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating preprocesors\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "catPreprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numPreprocessor = StandardScaler()\n",
    "\n",
    "# Transforming the data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', catPreprocessor, categoricalCols)],remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316e977",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b301164",
   "metadata": {},
   "source": [
    "#### Setting up some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner cross-validation(for Hyperparameter tuning)\n",
    "innerCV = StratifiedKFold(n_splits=5, shuffle=True, random_state=randomState)\n",
    "# Outer cross-validation(for testing the tunned model)\n",
    "outerCV = StratifiedKFold(n_splits=3, shuffle=True, random_state=randomState)\n",
    "\n",
    "scoring = {\"auc\": \"roc_auc\", \"f1_weighted\": \"f1_weighted\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fb5d8",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f7fc8",
   "metadata": {},
   "source": [
    "#### Will use nested CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a457d7",
   "metadata": {},
   "source": [
    "inner cross-validation(for Hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafa313",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Model\n",
    "model_DT = Pipeline([(\"classifier\", DecisionTreeClassifier(class_weight='balanced', random_state = randomState))])\n",
    "\n",
    "# Gridsearch params\n",
    "param_grid = {\n",
    "    'classifier__max_depth': (1,3,5,7,10),\n",
    "    'classifier__max_leaf_nodes': (1, 5,10,15,20),\n",
    "    'classifier__max_features': (1,3,5,7,10,15)\n",
    "}\n",
    "\n",
    "# Gridsearch\n",
    "model_grid_search_DT = GridSearchCV(model_DT,\n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring=scoring,\n",
    "                                    n_jobs=-1,\n",
    "                                    cv=innerCV,\n",
    "                                    return_train_score=True,\n",
    "                                    refit=False)\n",
    "\n",
    "_ = model_grid_search_DT.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsDT = [\"param_classifier__max_depth\",\n",
    "            'param_classifier__max_leaf_nodes',\n",
    "            \"param_classifier__max_features\"]\n",
    "\n",
    "getResults(model_grid_search_DT, paramsDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306783c",
   "metadata": {},
   "source": [
    "#### Selecting best parameters\n",
    "We will choose max_depth=7, max_features=5 and max_leaf_nodes=20. Reaching a compromise between F1 Score and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bestParamsDT = ['max_depth=7', 'max_leaf_nodes=20', 'max_features=5']\n",
    "\n",
    "modelDT = Pipeline([(\"classifier\", DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                        random_state = randomState,\n",
    "                                                        max_depth=7,\n",
    "                                                        max_leaf_nodes=20,\n",
    "                                                        max_features=15))])\n",
    "\n",
    "_ = modelDT.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51341248",
   "metadata": {},
   "source": [
    "Outer cross-validation(for testing the tunned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853e11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = getBestModelResults(modelDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b161c8",
   "metadata": {},
   "source": [
    "#### Curves and error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb260625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results['test_roc'], results['test_f1-score'] = getMeasures(modelDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5b88c",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceea95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "printResults(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26fb7c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_LR = Pipeline([(\"processor\", preprocessor),\n",
    "                  (\"classifier\", LogisticRegression(max_iter=1000,\n",
    "                                                    class_weight='balanced',\n",
    "                                                    random_state=randomState))])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': (1e-3, 1e-2, 0.1, 1, 5, 10, 20),\n",
    "}\n",
    "scoring = {\"auc\": \"roc_auc\", \"f1_weighted\": \"f1_weighted\"}\n",
    "\n",
    "model_grid_search_LR = GridSearchCV(model_LR,\n",
    "                                 param_grid=param_grid,\n",
    "                                 scoring=scoring,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=innerCV,\n",
    "                                 return_train_score=True,\n",
    "                                 refit=False)\n",
    "_ = model_grid_search_LR.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c93c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsLR = [\"param_classifier__C\"]\n",
    "\n",
    "getResults(model_grid_search_LR, paramsLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2fc15",
   "metadata": {},
   "source": [
    "#### Selecting best parameters\n",
    "Choosing C=0.1, in this case it's the beast AUC and 2nd best F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216821e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelLR = Pipeline([(\"classifier\", LogisticRegression(max_iter=1000,\n",
    "                                                    C=0.01,\n",
    "                                                    class_weight='balanced',\n",
    "                                                    random_state=randomState))])\n",
    "\n",
    "_ = modelLR.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b923c",
   "metadata": {},
   "source": [
    "Outer cross-validation(for testing the tunned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = getBestModelResults(modelLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8a8df",
   "metadata": {},
   "source": [
    "#### Curves and error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['test_roc'], results['test_f1-score'] = getMeasures(modelLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbfdd3",
   "metadata": {},
   "source": [
    "### Logistic Regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69482cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "printResults(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e1eb14",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295cebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_RF = Pipeline([(\"classifier\", RandomForestClassifier(n_estimators=10,\n",
    "                                                           class_weight='balanced',\n",
    "                                                           random_state=randomState))])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__max_depth': (5,10,15,20,25),\n",
    "    'classifier__max_leaf_nodes': (5,10,15,20,30),\n",
    "    'classifier__max_features': (3,5,7,10)\n",
    "}\n",
    "\n",
    "scoring = {\"auc\": \"roc_auc\", \"f1_weighted\": \"f1_weighted\"}\n",
    "\n",
    "model_grid_search_RF = GridSearchCV(model_RF,\n",
    "                                 param_grid=param_grid,\n",
    "                                 scoring=scoring,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=innerCV,\n",
    "                                 return_train_score=True,\n",
    "                                 refit=False)\n",
    "_ = model_grid_search_RF.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29856ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsRF = [\"param_classifier__max_depth\",\n",
    "            'param_classifier__max_leaf_nodes',\n",
    "            \"param_classifier__max_features\"]\n",
    "\n",
    "getResults(model_grid_search_RF, paramsRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b8c70",
   "metadata": {},
   "source": [
    "#### Selecting best parameters\n",
    "Choosing max_depth = 10, max_leaf_nodes=30 and max_features=10. It's a good AUC and a good F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelRF = Pipeline([(\"classifier\", RandomForestClassifier(n_estimators=10,\n",
    "                                                          max_depth = 10,\n",
    "                                                          max_leaf_nodes=30,\n",
    "                                                          max_features=10,\n",
    "                                                          class_weight='balanced',\n",
    "                                                          random_state=randomState))])\n",
    "\n",
    "_ = modelRF.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee3f0b",
   "metadata": {},
   "source": [
    "Outer cross-validation(for testing the tuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd469a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = getBestModelResults(modelRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f31eb6",
   "metadata": {},
   "source": [
    "#### Curves and error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['test_roc'], results['test_f1-score'] = getMeasures(modelRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2dfdbc",
   "metadata": {},
   "source": [
    "### Random Forest results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "printResults(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441eb2f7",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanceRatio = (yTrainFull==0).sum() / (yTrainFull==1).sum()\n",
    "imbalanceRatio = round(imbalanceRatio, 2)\n",
    "imbalanceRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e999f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 58 min 15 s\n",
    "# Inner cross-validation(for Hyperparameter tuning)\n",
    "innerCV = StratifiedKFold(n_splits=3, shuffle=True, random_state=randomState)\n",
    "\n",
    "model_XGB = Pipeline([(\"classifier\", XGBClassifier(n_estimators=10,\n",
    "                                                   random_state=randomState, \n",
    "                                                   tree_method='gpu_hist',\n",
    "                                                   scale_pos_weight=imbalanceRatio)\n",
    "                      )])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__max_depth' : (2, 5, 8, 10),\n",
    "    'classifier__learning_rate' : (0.01, 0.1, 0.5, 0.8),\n",
    "    'classifier__min_child_weight' : (1,10,20),\n",
    "    'classifier__reg_lambda' : (1, 3, 5, 8),\n",
    "}\n",
    "\n",
    "scoring = {\"auc\": \"roc_auc\", \"f1_weighted\": \"f1_weighted\"}\n",
    "\n",
    "model_grid_search_XGB = GridSearchCV(model_XGB,\n",
    "                                 param_grid=param_grid,\n",
    "                                 scoring=scoring,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=innerCV,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,                                 \n",
    "                                 refit=False)\n",
    "\n",
    "_ = model_grid_search_XGB.fit(dfTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce0a3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paramsXGB = [\"param_classifier__max_depth\",\n",
    "             'param_classifier__learning_rate',\n",
    "             \"param_classifier__min_child_weight\",\n",
    "             \"param_classifier__reg_lambda\"]\n",
    "\n",
    "getResults(model_grid_search_XGB, paramsXGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80094d4",
   "metadata": {},
   "source": [
    "#### Selecting best parameters\n",
    "Choosing max_depth = 8, learning_rate = 0.5, min_child_weight = 20 and reg_lambda = 8,. It's a good compromise between a good AUC and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelXGB = Pipeline([(\"classifier\", XGBClassifier(n_estimators = 10,\n",
    "                                                  max_depth = 5,\n",
    "                                                  learning_rate = 0.8,\n",
    "                                                  min_child_weight = 10,\n",
    "                                                  reg_lambda = 8,\n",
    "                                                  random_state=randomState, \n",
    "                                                  tree_method='gpu_hist',\n",
    "                                                  scale_pos_weight=imbalanceRatio))\n",
    "                    ])\n",
    "\n",
    "_ = modelXGB.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd98c9b",
   "metadata": {},
   "source": [
    "Outer cross-validation(for testing the tuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBestModelResults(modelXGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99fc9e4",
   "metadata": {},
   "source": [
    "#### Curves and measures of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db5653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = getMeasures(modelXGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76a751",
   "metadata": {},
   "source": [
    "### XGBoost results:\n",
    "| Measure           |    mean +/- std   |\n",
    "|:-                 |:-:                |\n",
    "| val f1_weighted   | 0.7505 +/- 0.0032 |\n",
    "| val roc_auc       | 0.7591 +/- 0.0033 |\n",
    "| train f1_weighted | 0.8114 +/- 0.0008 |\n",
    "| train roc_auc     | 0.835  +/- 0.0008 |\n",
    "|test f1_weighted   | 0.749             |\n",
    "|test roc_auc       | 0.813             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f41ac0",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_AB = Pipeline([(\"classifier\", AdaBoostClassifier(base_estimator = DecisionTreeClassifier(),\n",
    "                                                       random_state=randomState)\n",
    "                      )])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate' : (0.1, 0.5, 1, 2),\n",
    "    'classifier__base_estimator__class_weight': [None, 'balanced'],\n",
    "    'classifier__base_estimator__max_depth': [1, 3, 5],\n",
    "    'classifier__base_estimator__max_leaf_nodes': [1, 3, 5],\n",
    "    \n",
    "}\n",
    "\n",
    "scoring = {\"auc\": \"roc_auc\", \"f1_weighted\": \"f1_weighted\"}\n",
    "\n",
    "model_grid_search_AB = GridSearchCV(model_AB,\n",
    "                                 param_grid=param_grid,\n",
    "                                 scoring=scoring,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=innerCV,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,                                 \n",
    "                                 refit=False)\n",
    "\n",
    "_ = model_grid_search_AB.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsAB = ['param_classifier__learning_rate',\n",
    "            'param_classifier__base_estimator__class_weight',\n",
    "            'param_classifier__base_estimator__max_depth',\n",
    "            'param_classifier__base_estimator__max_leaf_nodes'\n",
    "           ]\n",
    "\n",
    "getResults(model_grid_search_AB, paramsAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511fdba",
   "metadata": {},
   "source": [
    "#### Selecting best parameters\n",
    "Choosing max_depth = 3, max_leaf_nodes= 3  and learning_rate = 0.8 and class_weight = None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelAB = Pipeline([(\"classifier\", AdaBoostClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(class_weight = 'balanced',\n",
    "                                            max_depth = 1,\n",
    "                                            max_leaf_nodes = 5,\n",
    "                                           ), learning_rate = 1.0, random_state=randomState))\n",
    "                   ])\n",
    "\n",
    "_ = modelAB.fit(dfTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a875d36",
   "metadata": {},
   "source": [
    "Outer cross-validation(for testing the tuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBestModelResults(modelAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b61f8e",
   "metadata": {},
   "source": [
    "#### Curves and error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bbf3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = getMeasures(modelAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcba748",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier results:\n",
    "| Measure           |    mean +/- std   |\n",
    "|:-                 |:-:                |\n",
    "| val f1_weighted   | 0.7551 +/- 0.0015 |\n",
    "| val roc_auc       | 0.7554 +/- 0.001  |\n",
    "| train f1_weighted | 0.8116 +/- 0.001 |\n",
    "| train roc_auc     | 0.8126 +/- 0.0006 |\n",
    "|test f1_weighted   | 0.756             |\n",
    "|test roc_auc       | 0.813             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e892612",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [modelDT, modelLR, modelRF, modelXGB, modelAB]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "delta = 0\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    yTestpredProb_ = model.predict_proba(dfTest)[:,1]\n",
    "    yTestpred_ = model.predict(dfTest)\n",
    "    modelName = type(model.named_steps.classifier).__name__\n",
    "    \n",
    "    auc = round(roc_auc_score(yTest, yTestpredProb_),3)\n",
    "    f1Score = round(f1_score(yTest, yTestpred_, average='weighted'),3)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(yTest.values, yTestpredProb_)\n",
    "    roc_display1 = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "    roc_display1.plot(ax=ax, name=modelName)\n",
    "    #roc_display1.ax_.(linestyle='dashed', marker='o')\n",
    "    roc_display1.ax_.set_title('ROC_AUC and F1 SCORE', size= 16)\n",
    "    ax.text(0.65, 0.155 - delta, f'auc = {auc}', size=14 )\n",
    "    ax.text(0.78, 0.155 - delta, f'weighted f1  = {f1Score}', size=14)\n",
    "    ax.legend(loc='lower center', prop={'size': 14})\n",
    "    delta += 0.043  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaec30c",
   "metadata": {},
   "source": [
    "#### In this case the best model is the AdaBoostClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bdb438",
   "metadata": {},
   "source": [
    "## Saving Models with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a847026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "models = [modelDT, modelLR, modelRF, modelXGB, modelAB]\n",
    "for model in models:\n",
    "    modelName = type(model.named_steps.classifier).__name__\n",
    "    print(f'Saving pickle file for {modelName}')\n",
    "    outputFile = f'models/{modelName}.bin'\n",
    "    with open(outputFile, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d6ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59ca42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853c8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15b67de5",
   "metadata": {},
   "source": [
    "## Testing model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = {\n",
    "    'highbp': 'No',\n",
    "    'highchol': 'Yes',\n",
    "     'cholcheck': 'Yes',\n",
    "     'bmi': 27,\n",
    "     'smoker': 'Yes',\n",
    "     'stroke': 'No',\n",
    "     'heartdiseaseorattack': 'No',\n",
    "     'physactivity': 'No',\n",
    "     'fruits': 'Yes',\n",
    "     'veggies': 'Yes',\n",
    "     'hvyalcoholconsump': 'No',\n",
    "     'anyhealthcare': 'No',\n",
    "     'nodocbccost': 'No',\n",
    "     'genhlth': 'Yes',\n",
    "     'menthlth': 0,\n",
    "     'physhlth': 0,\n",
    "     'diffwalk': 'No',\n",
    "     'sex': 'Female',\n",
    "     'age': 25,\n",
    "     'education': 'Some high school',\n",
    "     'income': '$25,000 to $35,000'\n",
    "}\n",
    "inputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform inputdata to an inputdataframe\n",
    "data = pd.DataFrame(inputData, index=[1])\n",
    "data.drop(columns=['nodocbccost', 'fruits', 'anyhealthcare', 'veggies'], inplace=True)\n",
    "# Mappings\n",
    "sex = {'Male':0, 'Female':1}\n",
    "binary = {'Yes': 1, 'No': 0}\n",
    "education = {'Never attended school or only kindergarten' : 1,\n",
    "             'Elementary school' : 2,\n",
    "             'Some high school' : 3,\n",
    "             'High school graduate' : 4,\n",
    "             'Some college or technical school' : 5,\n",
    "             'College graduate' : 6 }\n",
    "income = {'less than $10,000'  : 1,\n",
    "          '$10,000 to $15,000' : 2,\n",
    "          '$15,000 to $20,000' : 3, \n",
    "          '$20,000 to $25,000' : 4,\n",
    "          '$25,000 to $35,000' : 5,\n",
    "          '$35,000 to $50,000' : 6,\n",
    "          '$50,000 to $75,000' : 7,\n",
    "          '$75,000 or  more'   : 8}\n",
    "\n",
    "\n",
    "def getAgeRange(age):\n",
    "    \n",
    "    if 18 <= age <= 24:\n",
    "        ageRange = 1\n",
    "    elif 25 <= age <= 29:\n",
    "        ageRange = 2\n",
    "    elif 30 <= age <= 34: \n",
    "        ageRange = 3\n",
    "    elif 35 <= age <= 39: \n",
    "        ageRange = 4\n",
    "    elif 40 <= age <= 44:\n",
    "        ageRange = 5\n",
    "    elif 45 <= age <= 49:\n",
    "        ageRange = 6\n",
    "    elif 50 <= age <= 54:\n",
    "        ageRange = 7\n",
    "    elif 55 <= age <= 59:\n",
    "        ageRange = 8\n",
    "    elif 60 <= age <= 64:\n",
    "        ageRange = 9\n",
    "    elif 65 <= age <= 69:\n",
    "        ageRange = 10\n",
    "    elif 70 <= age <= 74:\n",
    "        ageRange = 11\n",
    "    elif 75 <= age <= 79:\n",
    "        ageRange = 12\n",
    "    elif 80 <= age:\n",
    "        ageRange = 13\n",
    "    return ageRange\n",
    "\n",
    "ageRange = getAgeRange(data.age.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values\n",
    "data.replace( binary | sex | education | income , inplace=True)\n",
    "data.age = ageRange\n",
    "\n",
    "# get models from folder and load models to a dictionary\n",
    "path = 'models/'\n",
    "files = os.listdir(path)\n",
    "models = {}\n",
    "\n",
    "for file in files:\n",
    "    filename = file.split('.')[0]\n",
    "    with open('models/' + file, 'rb') as f:\n",
    "        models[filename] = pickle.load(f)        \n",
    "\n",
    "# Make predictions\n",
    "for name, model in models.items():\n",
    "    yProb_ = model.predict_proba(data)[:,1]\n",
    "    yPred_ = model.predict(data)\n",
    "    print(f'{name:<22} : {yProb_} = {yPred_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData2 = {\n",
    "    'highbp': 'No',\n",
    "    'highchol': 'Yes',\n",
    "    'cholcheck': 'Yes',\n",
    "    'bmi': 30,\n",
    "    'smoker': 'Yes',\n",
    "    'stroke': 'No',\n",
    "    'heartdiseaseorattack': 'No',\n",
    "    'physactivity': 'Yes',\n",
    "    'fruits': 'Yes',\n",
    "    'veggies': 'Yes',\n",
    "    'hvyalcoholconsump': 'No',\n",
    "    'anyhealthcare': 'Yes',\n",
    "    'nodocbccost': 'No',\n",
    "    'genhlth': 'Yes',\n",
    "    'menthlth': 'No',\n",
    "    'physhlth': 'No',\n",
    "    'diffwalk': 'No',\n",
    "    'sex': 'Male',\n",
    "    'age': 57,\n",
    "    'education': 'High school graduate',\n",
    "    'income': '$75,000 or  more'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values\n",
    "data.replace( binary | sex | education | income , inplace=True)\n",
    "data.age = ageRange\n",
    "\n",
    "# get models from folder and load models to a dictionary\n",
    "path = 'models/'\n",
    "files = os.listdir(path)\n",
    "models = {}\n",
    "\n",
    "for file in files:\n",
    "    filename = file.split('.')[0]\n",
    "    with open('models/' + file, 'rb') as f:\n",
    "        models[filename] = pickle.load(f) \n",
    "        \n",
    "# Make predictions\n",
    "for name, model in models.items():\n",
    "    yProb_ = model.predict_proba(data)[:,1]\n",
    "    yPred_ = model.predict(data)\n",
    "    print(f'{name:<22} : {yProb_} = {yPred_}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77615bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
