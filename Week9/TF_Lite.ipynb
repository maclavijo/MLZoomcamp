{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad01d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Input\n",
    "from keras.models import load_model\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from keras_preprocessing.image import load_img, ImageDataGenerator\n",
    "from keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811992f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "#base_model = InceptionV3(include_top=False,\n",
    "#                         input_shape=(150, 150, 3),\n",
    "#                        weights = 'imagenet')\n",
    "#\n",
    "base_model.trainable = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c374559",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True\n",
    "                              )\n",
    "#rescale=1/255.)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory('../Week8/clothing-dataset-small/train/',\n",
    "                                         target_size=(300,300),                              \n",
    "                                         batch_size=20)\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)#rescale=1/255.)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory('../Week8/clothing-dataset-small/validation/',\n",
    "                                     target_size=(300,300),\n",
    "                                     batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(300,300,3))\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "#base = last_layer_out.output\n",
    "#x = layers.Flatten()(base_model.output)\n",
    "vectors = layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "#x = layers.Dense(16, activation='relu')(x)\n",
    "inner = layers.Dense(128, activation='relu')(vectors)\n",
    "drop = layers.Dropout(0.2)(inner)\n",
    "outputs = layers.Dense(10)(drop)\n",
    "#model = keras.Model(inputs, outputs)\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#modelx = Model(base_model.input, x)\n",
    "modelx = Model(inputs, outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "modelx.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e857c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelx.fit(train_ds,\n",
    "                     validation_data=val_ds,\n",
    "                     steps_per_epoch=50,\n",
    "                     epochs=10,\n",
    "                     #validation_steps=5,\n",
    "                     #verbose=2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2669e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx.save('clothing_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c949ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax = plt.plot(history.history['val_accuracy'], label='Val')\n",
    "ax = plt.plot(history.history['accuracy'], label='Train')\n",
    "    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = load_img('pants.jpg', target_size=(300,300))\n",
    "\n",
    "x = np.array(img2)\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)\n",
    "\n",
    "pred = modelx.predict(X)\n",
    "\n",
    "values = ['dress', 'hat', 'longsleeve',  'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "\n",
    "list(zip(values, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324621b0",
   "metadata": {},
   "source": [
    "### TF-Lite Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc753271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('clothing_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tflite.TFLiteConverter.from_keras_model(model)\n",
    "tfLiteModel = converter.convert()\n",
    "\n",
    "with open('clothing_model.tflite', 'wb') as f:\n",
    "    f.write(tfLiteModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path='clothing_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "inputIdx = interpreter.get_input_details()[0]['index']\n",
    "\n",
    "outputIdx = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "interpreter.set_tensor(inputIdx, X)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "pred = interpreter.get_tensor(outputIdx)\n",
    "\n",
    "values = ['dress', 'hat', 'longsleeve',  'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "\n",
    "list(zip(values, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c9d84",
   "metadata": {},
   "source": [
    "### Remove TF dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open('pants.jpg') as img:\n",
    "    img = img.resize((300,300), Image.Resampling.NEAREST)\n",
    "img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= -1.\n",
    "    return x\n",
    "\n",
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97969bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter2 = tflite.Interpreter(model_path='clothing_model.tflite')\n",
    "\n",
    "interpreter2.allocate_tensors()\n",
    "\n",
    "inputIdx = interpreter2.get_input_details()[0]['index']\n",
    "\n",
    "outputIdx = interpreter2.get_output_details()[0]['index']\n",
    "\n",
    "interpreter2.set_tensor(inputIdx, X)\n",
    "\n",
    "interpreter2.invoke()\n",
    "\n",
    "preds = interpreter2.get_tensor(outputIdx)\n",
    "\n",
    "values = ['dress', 'hat', 'longsleeve',  'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "\n",
    "list(zip(values, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb75a4a",
   "metadata": {},
   "source": [
    "### Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc79525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "import tflite_runtime.interpreter as tflite\n",
    "#from keras_preprocessing.image import load_img\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='clothing_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "inputIdx = interpreter.get_input_details()[0]['index']\n",
    "outputIdx = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "preprocessor = create_preprocessor('xception', target_size=(300,300))\n",
    "classes = ['dress', 'hat', 'longsleeve',  'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "\n",
    "# url = 'http://bit.ly/mlbookcamp-pants'\n",
    "\n",
    "def predict(url):\n",
    "    \n",
    "    X = preprocessor.from_url(url)\n",
    "    interpreter.set_tensor(inputIdx, X)\n",
    "    interpreter.invoke()\n",
    "    pred = interpreter.get_tensor(outputIdx)\n",
    "    \n",
    "    return dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d055ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dress', -0.9170631),\n",
       " ('hat', -3.8840833),\n",
       " ('longsleeve', -0.69299227),\n",
       " ('outwear', -0.96617234),\n",
       " ('pants', 8.59048),\n",
       " ('shirt', -1.4101405),\n",
       " ('shoes', -2.6699123),\n",
       " ('shorts', 6.206608),\n",
       " ('skirt', -0.20017798),\n",
       " ('t-shirt', -2.6417527)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "\n",
    "predict(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
